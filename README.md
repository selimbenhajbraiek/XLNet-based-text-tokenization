# XLNet-based-text-tokenization
This simple Python script demonstrates how to clean and tokenize text using the **XLNet tokenizer** from Hugging Face Transformers.

### Steps:
1. Load your dataset
2. Clean the text (remove emojis and punctuation)
3. Tokenize it using XLNet ('xlnet-base-cased')
4. Print the results

## Installation
git clone https://github.com/selimbenhajbraiek/XLNet-based-text-tokenization.git
cd XLNet-based-text-tokenization

pip install -r requirements.txt